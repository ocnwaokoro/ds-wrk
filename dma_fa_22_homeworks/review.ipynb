{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae80e0-3a0e-4704-b8b6-0e8a130b0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aebf18ab-c276-4cc1-a458-448c80a060a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kiwi'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"I ate 200 kiwis on May 8th, 1999\"\n",
    "m = re.search('(\\wi)+', s)\n",
    "m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf4d9489-e677-433e-9b14-45b7d51ced98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0   q8\n",
       "1   q9\n",
       "2  q10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['q8 - foo?', 'q9 - bar?', 'q10 - baz?'])\n",
    "s.str.extract('(q\\d+)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5b59ba4-91fd-4475-9543-66f6dd7445dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_ordered</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_Order</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          number_ordered  Price\n",
       "Day_Order                      \n",
       "Monday                 3    200\n",
       "Wednesday              3    200"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'item_number': [2,2,3,5,7],\n",
    "          'number_ordered': ['3','3','9','10','11'],\n",
    "          'Price': [200,200,400,1200,900],\n",
    "          'Day_Order':['Monday','Wednesday','Wednesday','Tuesday','Monday']\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.set_index(['item_number', 'Day_Order'])\n",
    "\n",
    "df.loc[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af340ba7-c889-4d19-aa71-6a8fe43f1894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teams</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>team1</th>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team2</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score\n",
       "teams       \n",
       "team1    150\n",
       "team2    200"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores = pd.DataFrame({\n",
    "    'teams': ['team1','team2','team2','team1','team2','team1'],\n",
    "    'score':[100,200,50,150,200,80]\n",
    "})\n",
    "\n",
    "op = scores.groupby('teams').max()\n",
    "op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a8b2972-7139-4a6b-89b4-7bba8ae4e88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'May 8th'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"I ate 200 kiwis on May 8th, 1999\"\n",
    "m = re.search('\\w+ (\\d[A-Za-z]{2})', s)\n",
    "m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ad9a10c-a0b7-4e20-a49d-a786b7f5c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            number_ordered  Price\n",
      "item_number                      \n",
      "2                        3    200\n",
      "2                        3    200\n",
      "3                        9    400\n",
      "5                       10   1200\n",
      "7                       11    900\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'item_number': ['2','2','3','5','7'],\n",
    "'number_ordered': ['3','3','9','10','11'],\n",
    "'Price': [200,200,400,1200,900]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['item_number','number_ordered','Price'])\n",
    "\n",
    "df = df.set_index('item_number')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1cde03e-f91f-4e51-b6b0-d926cf8446e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rac\n"
     ]
    }
   ],
   "source": [
    "s = 'abracadabra!'\n",
    "m = re.search('r[aeiou].', s) \n",
    "print(m[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fc8150f-e16d-4514-8060-ba7d62965707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abrac\n"
     ]
    }
   ],
   "source": [
    "print(s[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1abe1bc9-6fab-4dea-9804-d571864d389e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "apple         50\n",
       "asparagus    500\n",
       "banana        25\n",
       "broccoli     200\n",
       "orange       125\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory = [\n",
    "    ['banana', 'fruit', 25], \n",
    "    ['orange', 'fruit', 125], \n",
    "    ['broccoli', 'vegetable', 200], \n",
    "    ['apple', 'fruit', 50], \n",
    "    ['asparagus', 'vegetable', 500] \n",
    "]\n",
    "columns = ['name', 'category', 'price']\n",
    "df = pd.DataFrame(inventory, columns=columns)\n",
    "df['price'].groupby(df['name']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f8d0966-b17b-4e46-ad03-6e3b4b9d42bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "fruit         66.666667\n",
       "vegetable    350.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory = [\n",
    "    ['banana', 'fruit', 25], \n",
    "    ['orange', 'fruit', 125], \n",
    "    ['broccoli', 'vegetable', 200], \n",
    "    ['apple', 'fruit', 50], \n",
    "    ['asparagus', 'vegetable', 500] \n",
    "]\n",
    "columns = ['name', 'category', 'price']\n",
    "df = pd.DataFrame(inventory, columns=columns)\n",
    "df['price'].groupby(df['category']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a13b279-7225-4d44-b1c8-27e0dc41a7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SeriesGroupBy in module pandas.core.groupby.generic object:\n",
      "\n",
      "class SeriesGroupBy(pandas.core.groupby.groupby.GroupBy)\n",
      " |  SeriesGroupBy(obj: 'NDFrameT', keys: '_KeysArgType | None' = None, axis: 'int' = 0, level: 'IndexLabel | None' = None, grouper: 'ops.BaseGrouper | None' = None, exclusions: 'frozenset[Hashable] | None' = None, selection: 'IndexLabel | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, squeeze: 'bool' = False, observed: 'bool' = False, mutated: 'bool' = False, dropna: 'bool' = True)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SeriesGroupBy\n",
      " |      pandas.core.groupby.groupby.GroupBy\n",
      " |      pandas.core.groupby.groupby.BaseGroupBy\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      typing.Generic\n",
      " |      pandas.core.groupby.indexing.GroupByIndexingMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  agg = aggregate(self, func=None, *args, engine=None, engine_kwargs=None, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func=None, *args, engine=None, engine_kwargs=None, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      \n",
      " |          Can also accept a Numba JIT function with\n",
      " |          ``engine='numba'`` specified. Only passing a single function is supported\n",
      " |          with this engine.\n",
      " |      \n",
      " |          If the ``'numba'`` engine is chosen, the function must be\n",
      " |          a user defined function with ``values`` and ``index`` as the\n",
      " |          first and second arguments respectively in the function signature.\n",
      " |          Each group's index will be passed to the user defined function\n",
      " |          and optionally available for use.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      *args\n",
      " |          Positional arguments to pass to func.\n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the function through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the function through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |            applied to the function\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      **kwargs\n",
      " |          Keyword arguments to be passed into func.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby.apply : Apply function func group-wise\n",
      " |          and combine the results together.\n",
      " |      Series.groupby.transform : Aggregate using one or more\n",
      " |          operations over the specified axis.\n",
      " |      Series.aggregate : Transforms the Series on each group\n",
      " |          based on the given function.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When using ``engine='numba'``, there will be no \"fall back\" behavior internally.\n",
      " |      The group data and group index will be passed as numpy arrays to the JITed\n",
      " |      user defined function, and no alternative execution attempts will be tried.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |          see the examples below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      \n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.groupby([1, 1, 2, 2]).min()\n",
      " |      1    1\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.groupby([1, 1, 2, 2]).agg('min')\n",
      " |      1    1\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.groupby([1, 1, 2, 2]).agg(['min', 'max'])\n",
      " |         min  max\n",
      " |      1    1    2\n",
      " |      2    3    4\n",
      " |      \n",
      " |      The output column names can be controlled by passing\n",
      " |      the desired column names and aggregations as keyword arguments.\n",
      " |      \n",
      " |      >>> s.groupby([1, 1, 2, 2]).agg(\n",
      " |      ...     minimum='min',\n",
      " |      ...     maximum='max',\n",
      " |      ... )\n",
      " |         minimum  maximum\n",
      " |      1        1        2\n",
      " |      2        3        4\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the aggregating function.\n",
      " |      \n",
      " |      >>> s.groupby([1, 1, 2, 2]).agg(lambda x: x.astype(float).min())\n",
      " |      1    1.0\n",
      " |      2    3.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  apply(self, func, *args, **kwargs)\n",
      " |      Apply function ``func`` group-wise and combine the results together.\n",
      " |      \n",
      " |      The function passed to ``apply`` must take a series as its first\n",
      " |      argument and return a DataFrame, Series or scalar. ``apply`` will\n",
      " |      then take care of combining the results back together into a single\n",
      " |      dataframe or series. ``apply`` is therefore a highly flexible\n",
      " |      grouping method.\n",
      " |      \n",
      " |      While ``apply`` is a very flexible method, its downside is that\n",
      " |      using it can be quite a bit slower than using more specific methods\n",
      " |      like ``agg`` or ``transform``. Pandas offers a wide range of method that will\n",
      " |      be much faster than using ``apply`` for their specific purposes, so try to\n",
      " |      use them before reaching for ``apply``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable\n",
      " |          A callable that takes a series as its first argument, and\n",
      " |          returns a dataframe, a series or a scalar. In addition the\n",
      " |          callable may take positional and keyword arguments.\n",
      " |      args, kwargs : tuple and dict\n",
      " |          Optional positional and keyword arguments to pass to ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pipe : Apply function to the full GroupBy object instead of to each\n",
      " |          group.\n",
      " |      aggregate : Apply aggregate function to the GroupBy object.\n",
      " |      transform : Apply function column-by-column to the GroupBy object.\n",
      " |      Series.apply : Apply a function to a Series.\n",
      " |      DataFrame.apply : Apply a function to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |          see the examples below.\n",
      " |      \n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, 2], index='a a b'.split())\n",
      " |      >>> g = s.groupby(s.index)\n",
      " |      \n",
      " |      From ``s`` above we can see that ``g`` has two groups, ``a`` and ``b``.\n",
      " |      Calling `apply` in various ways, we can get different grouping results:\n",
      " |      \n",
      " |      Example 1: The function passed to `apply` takes a Series as\n",
      " |      its argument and returns a Series.  `apply` combines the result for\n",
      " |      each group together into a new Series.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``.\n",
      " |      \n",
      " |      >>> g.apply(lambda x: x*2 if x.name == 'a' else x/2)\n",
      " |      a    0.0\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Example 2: The function passed to `apply` takes a Series as\n",
      " |      its argument and returns a scalar. `apply` combines the result for\n",
      " |      each group together into a Series, including setting the index as\n",
      " |      appropriate:\n",
      " |      \n",
      " |      >>> g.apply(lambda x: x.max() - x.min())\n",
      " |      a    1\n",
      " |      b    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  describe(self, **kwargs)\n",
      " |      Generate descriptive statistics.\n",
      " |      \n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(exclude=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      datetime_is_numeric : bool, default False\n",
      " |          Whether to treat datetime dtypes as numeric. This affects statistics\n",
      " |          calculated for the column. For DataFrame input, this also\n",
      " |          controls whether datetime columns are included by default.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe(datetime_is_numeric=True)\n",
      " |      count                      3\n",
      " |      mean     2006-09-01 08:00:00\n",
      " |      min      2000-01-01 00:00:00\n",
      " |      25%      2004-12-31 12:00:00\n",
      " |      50%      2010-01-01 00:00:00\n",
      " |      75%      2010-01-01 00:00:00\n",
      " |      max      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')  # doctest: +SKIP\n",
      " |             categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      a\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[object])  # doctest: +SKIP\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         a\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              d\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])  # doctest: +SKIP\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      a\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[object])  # doctest: +SKIP\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  filter(self, func, dropna: 'bool' = True, *args, **kwargs)\n",
      " |      Return a copy of a Series excluding elements from groups that\n",
      " |      do not satisfy the boolean criterion specified by func.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          To apply to each group. Should return True or False.\n",
      " |      dropna : Drop groups that do not pass the filter. True by default;\n",
      " |          if False, groups that evaluate False are filled with NaNs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Functions that mutate the passed object can produce unexpected\n",
      " |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      " |      for more details.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : [1, 2, 3, 4, 5, 6],\n",
      " |      ...                    'C' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> df.groupby('A').B.filter(lambda x: x.mean() > 3.)\n",
      " |      1    2\n",
      " |      3    4\n",
      " |      5    6\n",
      " |      Name: B, dtype: int64\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filtered : Series\n",
      " |  \n",
      " |  nlargest(self, n: 'int' = 5, keep: 'str' = 'first')\n",
      " |      Return the largest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Return this many descending sorted values.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          When there are duplicate values that cannot all fit in a\n",
      " |          Series of `n` elements:\n",
      " |      \n",
      " |          - ``first`` : return the first `n` occurrences in order\n",
      " |            of appearance.\n",
      " |          - ``last`` : return the last `n` occurrences in reverse\n",
      " |            order of appearance.\n",
      " |          - ``all`` : keep all occurrences. This can result in a Series of\n",
      " |            size larger than `n`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The `n` largest values in the Series, sorted in decreasing order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest: Get the `n` smallest elements.\n",
      " |      Series.sort_values: Sort Series by values.\n",
      " |      Series.head: Return the first `n` rows.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      " |      relative to the size of the ``Series`` object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
      " |      ...                         \"Malta\": 434000, \"Maldives\": 434000,\n",
      " |      ...                         \"Brunei\": 434000, \"Iceland\": 337000,\n",
      " |      ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
      " |      ...                         \"Anguilla\": 11300, \"Montserrat\": 5200}\n",
      " |      >>> s = pd.Series(countries_population)\n",
      " |      >>> s\n",
      " |      Italy       59000000\n",
      " |      France      65000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      Iceland       337000\n",
      " |      Nauru          11300\n",
      " |      Tuvalu         11300\n",
      " |      Anguilla       11300\n",
      " |      Montserrat      5200\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=5`` by default.\n",
      " |      \n",
      " |      >>> s.nlargest()\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=3``. Default `keep` value is 'first'\n",
      " |      so Malta will be kept.\n",
      " |      \n",
      " |      >>> s.nlargest(3)\n",
      " |      France    65000000\n",
      " |      Italy     59000000\n",
      " |      Malta       434000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=3`` and keeping the last duplicates.\n",
      " |      Brunei will be kept since it is the last with value 434000 based on\n",
      " |      the index order.\n",
      " |      \n",
      " |      >>> s.nlargest(3, keep='last')\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=3`` with all duplicates kept. Note\n",
      " |      that the returned Series has five elements due to the three duplicates.\n",
      " |      \n",
      " |      >>> s.nlargest(3, keep='all')\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  nsmallest(self, n: 'int' = 5, keep: 'str' = 'first')\n",
      " |      Return the smallest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Return this many ascending sorted values.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          When there are duplicate values that cannot all fit in a\n",
      " |          Series of `n` elements:\n",
      " |      \n",
      " |          - ``first`` : return the first `n` occurrences in order\n",
      " |            of appearance.\n",
      " |          - ``last`` : return the last `n` occurrences in reverse\n",
      " |            order of appearance.\n",
      " |          - ``all`` : keep all occurrences. This can result in a Series of\n",
      " |            size larger than `n`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The `n` smallest values in the Series, sorted in increasing order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest: Get the `n` largest elements.\n",
      " |      Series.sort_values: Sort Series by values.\n",
      " |      Series.head: Return the first `n` rows.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
      " |      ...                         \"Brunei\": 434000, \"Malta\": 434000,\n",
      " |      ...                         \"Maldives\": 434000, \"Iceland\": 337000,\n",
      " |      ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
      " |      ...                         \"Anguilla\": 11300, \"Montserrat\": 5200}\n",
      " |      >>> s = pd.Series(countries_population)\n",
      " |      >>> s\n",
      " |      Italy       59000000\n",
      " |      France      65000000\n",
      " |      Brunei        434000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Iceland       337000\n",
      " |      Nauru          11300\n",
      " |      Tuvalu         11300\n",
      " |      Anguilla       11300\n",
      " |      Montserrat      5200\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=5`` by default.\n",
      " |      \n",
      " |      >>> s.nsmallest()\n",
      " |      Montserrat    5200\n",
      " |      Nauru        11300\n",
      " |      Tuvalu       11300\n",
      " |      Anguilla     11300\n",
      " |      Iceland     337000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=3``. Default `keep` value is\n",
      " |      'first' so Nauru and Tuvalu will be kept.\n",
      " |      \n",
      " |      >>> s.nsmallest(3)\n",
      " |      Montserrat   5200\n",
      " |      Nauru       11300\n",
      " |      Tuvalu      11300\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=3`` and keeping the last\n",
      " |      duplicates. Anguilla and Tuvalu will be kept since they are the last\n",
      " |      with value 11300 based on the index order.\n",
      " |      \n",
      " |      >>> s.nsmallest(3, keep='last')\n",
      " |      Montserrat   5200\n",
      " |      Anguilla    11300\n",
      " |      Tuvalu      11300\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=3`` with all duplicates kept. Note\n",
      " |      that the returned Series has four elements due to the three duplicates.\n",
      " |      \n",
      " |      >>> s.nsmallest(3, keep='all')\n",
      " |      Montserrat   5200\n",
      " |      Nauru       11300\n",
      " |      Tuvalu      11300\n",
      " |      Anguilla    11300\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  nunique(self, dropna: 'bool' = True) -> 'Series'\n",
      " |      Return number of unique elements in the group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Number of unique values within each group.\n",
      " |  \n",
      " |  transform(self, func, *args, engine=None, engine_kwargs=None, **kwargs)\n",
      " |      Call function producing a like-indexed Series on each group and\n",
      " |      return a Series having the same indexes as the original object\n",
      " |      filled with the transformed values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      f : function\n",
      " |          Function to apply to each group.\n",
      " |      \n",
      " |          Can also accept a Numba JIT function with\n",
      " |          ``engine='numba'`` specified.\n",
      " |      \n",
      " |          If the ``'numba'`` engine is chosen, the function must be\n",
      " |          a user defined function with ``values`` and ``index`` as the\n",
      " |          first and second arguments respectively in the function signature.\n",
      " |          Each group's index will be passed to the user defined function\n",
      " |          and optionally available for use.\n",
      " |      \n",
      " |          .. versionchanged:: 1.1.0\n",
      " |      *args\n",
      " |          Positional arguments to pass to func.\n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the function through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the function through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or the global setting ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{'nopython': True, 'nogil': False, 'parallel': False}`` and will be\n",
      " |            applied to the function\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      **kwargs\n",
      " |          Keyword arguments to be passed into func.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby.apply : Apply function ``func`` group-wise and combine\n",
      " |          the results together.\n",
      " |      Series.groupby.aggregate : Aggregate using one or more\n",
      " |          operations over the specified axis.\n",
      " |      Series.transform : Call ``func`` on self producing a Series with the\n",
      " |          same axis shape as self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Each group is endowed the attribute 'name' in case you need to know\n",
      " |      which group you are working on.\n",
      " |      \n",
      " |      The current implementation imposes three requirements on f:\n",
      " |      \n",
      " |      * f must return a value that either has the same shape as the input\n",
      " |        subframe or can be broadcast to the shape of the input subframe.\n",
      " |        For example, if `f` returns a scalar it will be broadcast to have the\n",
      " |        same shape as the input subframe.\n",
      " |      * if this is a DataFrame, f must support application column-by-column\n",
      " |        in the subframe. If f also supports application to the entire subframe,\n",
      " |        then a fast path is used starting from the second chunk.\n",
      " |      * f must not mutate groups. Mutation is not supported and may\n",
      " |        produce unexpected results. See :ref:`gotchas.udf-mutation` for more details.\n",
      " |      \n",
      " |      When using ``engine='numba'``, there will be no \"fall back\" behavior internally.\n",
      " |      The group data and group index will be passed as numpy arrays to the JITed\n",
      " |      user defined function, and no alternative execution attempts will be tried.\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |          see the examples below.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
      " |      ...                           'foo', 'bar'],\n",
      " |      ...                    'B' : ['one', 'one', 'two', 'three',\n",
      " |      ...                           'two', 'two'],\n",
      " |      ...                    'C' : [1, 5, 5, 2, 5, 5],\n",
      " |      ...                    'D' : [2.0, 5., 8., 1., 2., 9.]})\n",
      " |      >>> grouped = df.groupby('A')\n",
      " |      >>> grouped.transform(lambda x: (x - x.mean()) / x.std())\n",
      " |                C         D\n",
      " |      0 -1.154701 -0.577350\n",
      " |      1  0.577350  0.000000\n",
      " |      2  0.577350  1.154701\n",
      " |      3 -1.154701 -1.000000\n",
      " |      4  0.577350 -0.577350\n",
      " |      5  0.577350  1.000000\n",
      " |      \n",
      " |      Broadcast result of the transformation\n",
      " |      \n",
      " |      >>> grouped.transform(lambda x: x.max() - x.min())\n",
      " |         C    D\n",
      " |      0  4  6.0\n",
      " |      1  3  8.0\n",
      " |      2  4  6.0\n",
      " |      3  3  8.0\n",
      " |      4  4  6.0\n",
      " |      5  3  8.0\n",
      " |      \n",
      " |      .. versionchanged:: 1.3.0\n",
      " |      \n",
      " |          The resulting dtype will reflect the return value of the passed ``func``,\n",
      " |          for example:\n",
      " |      \n",
      " |      >>> grouped[['C', 'D']].transform(lambda x: x.astype(int).max())\n",
      " |         C  D\n",
      " |      0  5  8\n",
      " |      1  5  9\n",
      " |      2  5  8\n",
      " |      3  5  9\n",
      " |      4  5  8\n",
      " |      5  5  9\n",
      " |  \n",
      " |  value_counts(self, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, bins=None, dropna: 'bool' = True)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  corr\n",
      " |      Compute correlation with `other` Series, excluding missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          Series with which to compute the correlation.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method used to compute correlation:\n",
      " |      \n",
      " |          - pearson : Standard correlation coefficient\n",
      " |          - kendall : Kendall Tau correlation coefficient\n",
      " |          - spearman : Spearman rank correlation\n",
      " |          - callable: Callable with input two 1d ndarrays and returning a float.\n",
      " |      \n",
      " |          .. warning::\n",
      " |              Note that the returned matrix from corr will have 1 along the\n",
      " |              diagonals and will be symmetric regardless of the callable's\n",
      " |              behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Correlation with other.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.corr : Compute pairwise correlation between columns.\n",
      " |      DataFrame.corrwith : Compute pairwise correlation with another\n",
      " |          DataFrame or Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> s1 = pd.Series([.2, .0, .6, .2])\n",
      " |      >>> s2 = pd.Series([.3, .6, .0, .1])\n",
      " |      >>> s1.corr(s2, method=histogram_intersection)\n",
      " |      0.3\n",
      " |  \n",
      " |  cov\n",
      " |      Compute covariance with Series, excluding missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          Series with which to compute the covariance.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result.\n",
      " |      ddof : int, default 1\n",
      " |          Delta degrees of freedom.  The divisor used in calculations\n",
      " |          is ``N - ddof``, where ``N`` represents the number of elements.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Covariance between Series and other normalized by N-1\n",
      " |          (unbiased estimator).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.cov : Compute pairwise covariance of columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\n",
      " |      >>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\n",
      " |      >>> s1.cov(s2)\n",
      " |      -0.01685762652715874\n",
      " |  \n",
      " |  diff\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a Series element compared with another\n",
      " |      element in the Series (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          First differences of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pct_change: Percent change over given number of periods.\n",
      " |      Series.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      DataFrame.diff: First discrete difference of object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      " |      :meth:`operator.sub`.\n",
      " |      The result is calculated according to current dtype in Series,\n",
      " |      however dtype of the result is always float64.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n",
      " |      >>> s.diff()\n",
      " |      0    NaN\n",
      " |      1    0.0\n",
      " |      2    1.0\n",
      " |      3    1.0\n",
      " |      4    2.0\n",
      " |      5    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> s.diff(periods=3)\n",
      " |      0    NaN\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    2.0\n",
      " |      4    4.0\n",
      " |      5    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> s.diff(periods=-1)\n",
      " |      0    0.0\n",
      " |      1   -1.0\n",
      " |      2   -1.0\n",
      " |      3   -2.0\n",
      " |      4   -3.0\n",
      " |      5    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Overflow in input dtype\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 0], dtype=np.uint8)\n",
      " |      >>> s.diff()\n",
      " |      0      NaN\n",
      " |      1    255.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  dtype\n",
      " |      Return the dtype object of the underlying data.\n",
      " |  \n",
      " |  fillna\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use next valid observation to fill gap.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Axis along which to fill missing values.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex : Conform object to new index.\n",
      " |      asfreq : Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, np.nan],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list(\"ABCD\"))\n",
      " |      >>> df\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  NaN  NaN NaN  NaN\n",
      " |      3  NaN  3.0 NaN  4.0\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  0.0\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method=\"ffill\")\n",
      " |           A    B   C    D\n",
      " |      0  NaN  2.0 NaN  0.0\n",
      " |      1  3.0  4.0 NaN  1.0\n",
      " |      2  3.0  4.0 NaN  1.0\n",
      " |      3  3.0  3.0 NaN  4.0\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  2.0  1.0\n",
      " |      2  0.0  1.0  2.0  3.0\n",
      " |      3  0.0  3.0  2.0  4.0\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  2.0  0.0\n",
      " |      1  3.0  4.0  NaN  1.0\n",
      " |      2  NaN  1.0  NaN  3.0\n",
      " |      3  NaN  3.0  NaN  4.0\n",
      " |      \n",
      " |      When filling using a DataFrame, replacement happens along\n",
      " |      the same column names and same indices\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\n",
      " |      >>> df.fillna(df2)\n",
      " |           A    B    C    D\n",
      " |      0  0.0  2.0  0.0  0.0\n",
      " |      1  3.0  4.0  0.0  1.0\n",
      " |      2  0.0  0.0  0.0  NaN\n",
      " |      3  0.0  3.0  0.0  4.0\n",
      " |      \n",
      " |      Note that column D is not affected since it is not present in df2.\n",
      " |  \n",
      " |  hist\n",
      " |      Draw histogram of the input series using matplotlib.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca().\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels.\n",
      " |      figsize : tuple, default None\n",
      " |          Figure size in inches by default.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      legend : bool, default False\n",
      " |          Whether to show the legend.\n",
      " |      \n",
      " |          .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          To be passed to the actual plotting function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot\n",
      " |          A histogram plot.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.axes.Axes.hist : Plot a histogram using matplotlib.\n",
      " |  \n",
      " |  idxmax\n",
      " |      Return the row label of the maximum value.\n",
      " |      \n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      " |          on Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords have no effect but might be\n",
      " |          accepted for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Label of the maximum value.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  idxmin\n",
      " |      Return the row label of the minimum value.\n",
      " |      \n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      " |          on Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords have no effect but might be\n",
      " |          accepted for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Label of the minimum value.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A', 'B', 'C', 'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  is_monotonic_decreasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_decreasing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  is_monotonic_increasing\n",
      " |      Alias for is_monotonic.\n",
      " |  \n",
      " |  mad\n",
      " |      Return the mean absolute deviation of the values over the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  skew\n",
      " |      Return unbiased skew over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  take\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      is_copy : bool\n",
      " |          Before pandas 1.0, ``is_copy=False`` can be specified to ensure\n",
      " |          that the return value is an actual copy. Starting with pandas 1.0,\n",
      " |          ``take`` always returns a copy, and the keyword is therefore\n",
      " |          deprecated.\n",
      " |      \n",
      " |          .. deprecated:: 1.0.0\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  tshift\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      .. deprecated:: 1.1.0\n",
      " |          Use `shift` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      freq : DateOffset, timedelta, or str, default None\n",
      " |          Increment to use from the tseries module\n",
      " |          or time rule expressed as a string (e.g. 'EOM').\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
      " |          Corresponds to the axis that contains the Index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series/DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |  \n",
      " |  unique\n",
      " |      Return unique values of Series object.\n",
      " |      \n",
      " |      Uniques are returned in order of appearance. Hash table-based unique,\n",
      " |      therefore does NOT sort.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray or ExtensionArray\n",
      " |          The unique values returned as a NumPy array. See Notes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      unique : Top-level unique method for any 1-d array-like object.\n",
      " |      Index.unique : Return Index with unique values from an Index object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the unique values as a NumPy array. In case of an\n",
      " |      extension-array backed Series, a new\n",
      " |      :class:`~api.extensions.ExtensionArray` of that type with just\n",
      " |      the unique values is returned. This includes\n",
      " |      \n",
      " |          * Categorical\n",
      " |          * Period\n",
      " |          * Datetime with Timezone\n",
      " |          * Interval\n",
      " |          * Sparse\n",
      " |          * IntegerNA\n",
      " |      \n",
      " |      See Examples section.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([2, 1, 3, 3], name='A').unique()\n",
      " |      array([2, 1, 3])\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n",
      " |      array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n",
      " |      ...            for _ in range(3)]).unique()\n",
      " |      <DatetimeArray>\n",
      " |      ['2016-01-01 00:00:00-05:00']\n",
      " |      Length: 1, dtype: datetime64[ns, US/Eastern]\n",
      " |      \n",
      " |      An Categorical will return categories in the order of\n",
      " |      appearance and with the same dtype.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n",
      " |      ['b', 'a', 'c']\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n",
      " |      ...                          ordered=True)).unique()\n",
      " |      ['b', 'a', 'c']\n",
      " |      Categories (3, object): ['a' < 'b' < 'c']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __orig_bases__ = (pandas.core.groupby.groupby.GroupBy[pandas.core.seri...\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby.GroupBy:\n",
      " |  \n",
      " |  __getattr__(self, attr: 'str')\n",
      " |  \n",
      " |  __getattribute__(self, attr: 'str')\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __init__(self, obj: 'NDFrameT', keys: '_KeysArgType | None' = None, axis: 'int' = 0, level: 'IndexLabel | None' = None, grouper: 'ops.BaseGrouper | None' = None, exclusions: 'frozenset[Hashable] | None' = None, selection: 'IndexLabel | None' = None, as_index: 'bool' = True, sort: 'bool' = True, group_keys: 'bool' = True, squeeze: 'bool' = False, observed: 'bool' = False, mutated: 'bool' = False, dropna: 'bool' = True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  all(self, skipna: 'bool' = True)\n",
      " |      Return True if all values in the group are truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          DataFrame or Series of boolean values, where a value is True if all elements\n",
      " |          are True within its respective group, False otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  any(self, skipna: 'bool' = True)\n",
      " |      Return True if any value in the group is truthful, else False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      skipna : bool, default True\n",
      " |          Flag to ignore nan values during truth testing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          DataFrame or Series of boolean values, where a value is True if any element\n",
      " |          is True within its respective group, False otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  backfill(self, limit=None)\n",
      " |      Backward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : int, optional\n",
      " |          Limit of how many values to fill.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object with missing values filled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.bfill :  Backward fill the missing values in the dataset.\n",
      " |      DataFrame.bfill:  Backward fill the missing values in the dataset.\n",
      " |      Series.fillna: Fill NaN values of a Series.\n",
      " |      DataFrame.fillna: Fill NaN values of a DataFrame.\n",
      " |  \n",
      " |  bfill(self, limit=None)\n",
      " |      Backward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : int, optional\n",
      " |          Limit of how many values to fill.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object with missing values filled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.bfill :  Backward fill the missing values in the dataset.\n",
      " |      DataFrame.bfill:  Backward fill the missing values in the dataset.\n",
      " |      Series.fillna: Fill NaN values of a Series.\n",
      " |      DataFrame.fillna: Fill NaN values of a DataFrame.\n",
      " |  \n",
      " |  count(self) -> 'Series | DataFrame'\n",
      " |      Compute count of group, excluding missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Count of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  cumcount(self, ascending: 'bool' = True)\n",
      " |      Number each item in each group from 0 to the length of that group - 1.\n",
      " |      \n",
      " |      Essentially this is equivalent to\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          self.apply(lambda x: pd.Series(np.arange(len(x)), x.index))\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from length of group - 1 to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Sequence number of each element within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .ngroup : Number the groups themselves.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],\n",
      " |      ...                   columns=['A'])\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').cumcount()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    0\n",
      " |      4    1\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').cumcount(ascending=False)\n",
      " |      0    3\n",
      " |      1    2\n",
      " |      2    1\n",
      " |      3    1\n",
      " |      4    0\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  cummax(self, axis=0, **kwargs)\n",
      " |      Cumulative max for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  cummin(self, axis=0, **kwargs)\n",
      " |      Cumulative min for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  cumprod(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative product for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  cumsum(self, axis=0, *args, **kwargs)\n",
      " |      Cumulative sum for each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  ewm(self, *args, **kwargs)\n",
      " |      Return an ewm grouper, providing ewm functionality per group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  expanding(self, *args, **kwargs)\n",
      " |      Return an expanding grouper, providing expanding\n",
      " |      functionality per group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  ffill(self, limit=None)\n",
      " |      Forward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : int, optional\n",
      " |          Limit of how many values to fill.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object with missing values filled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.ffill: Returns Series with minimum number of char in object.\n",
      " |      DataFrame.ffill: Object with missing values filled or None if inplace=True.\n",
      " |      Series.fillna: Fill NaN values of a Series.\n",
      " |      DataFrame.fillna: Fill NaN values of a DataFrame.\n",
      " |  \n",
      " |  first(self, numeric_only: 'bool' = False, min_count: 'int' = -1)\n",
      " |      Compute first of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data.\n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed first of values within each group.\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Return first n rows of each group.\n",
      " |      \n",
      " |      Similar to ``.apply(lambda x: x.head(n))``, but it returns a subset of rows\n",
      " |      from the original DataFrame with original index and order preserved\n",
      " |      (``as_index`` flag is ignored).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          If positive: number of entries to include from start of each group.\n",
      " |          If negative: number of entries to exclude from end of each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Subset of original Series or DataFrame as determined by n.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [1, 4], [5, 6]],\n",
      " |      ...                   columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').head(1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      2  5  6\n",
      " |      >>> df.groupby('A').head(-1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |  \n",
      " |  last(self, numeric_only: 'bool' = False, min_count: 'int' = -1)\n",
      " |      Compute last of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data.\n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed last of values within each group.\n",
      " |  \n",
      " |  max(self, numeric_only: 'bool' = False, min_count: 'int' = -1)\n",
      " |      Compute max of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data.\n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed max of values within each group.\n",
      " |  \n",
      " |  mean(self, numeric_only: 'bool | lib.NoDefault' = <no_default>, engine: 'str' = 'cython', engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute mean of groups, excluding missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default True\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data.\n",
      " |      \n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the operation through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the operation through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting\n",
      " |            ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{{'nopython': True, 'nogil': False, 'parallel': False}}``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Series or pandas.DataFrame\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5],\n",
      " |      ...                    'C': [1, 2, 1, 1, 2]}, columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Groupby one column and return the mean of the remaining columns in\n",
      " |      each group.\n",
      " |      \n",
      " |      >>> df.groupby('A').mean()\n",
      " |           B         C\n",
      " |      A\n",
      " |      1  3.0  1.333333\n",
      " |      2  4.0  1.500000\n",
      " |      \n",
      " |      Groupby two columns and return the mean of the remaining column.\n",
      " |      \n",
      " |      >>> df.groupby(['A', 'B']).mean()\n",
      " |               C\n",
      " |      A B\n",
      " |      1 2.0  2.0\n",
      " |        4.0  1.0\n",
      " |      2 3.0  1.0\n",
      " |        5.0  2.0\n",
      " |      \n",
      " |      Groupby one column and return the mean of only particular column in\n",
      " |      the group.\n",
      " |      \n",
      " |      >>> df.groupby('A')['B'].mean()\n",
      " |      A\n",
      " |      1    3.0\n",
      " |      2    4.0\n",
      " |      Name: B, dtype: float64\n",
      " |  \n",
      " |  median(self, numeric_only: 'bool | lib.NoDefault' = <no_default>)\n",
      " |      Compute median of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default True\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Median of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  min(self, numeric_only: 'bool' = False, min_count: 'int' = -1)\n",
      " |      Compute min of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default False\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data.\n",
      " |      min_count : int, default -1\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed min of values within each group.\n",
      " |  \n",
      " |  ngroup(self, ascending: 'bool' = True)\n",
      " |      Number each group from 0 to the number of groups - 1.\n",
      " |      \n",
      " |      This is the enumerative complement of cumcount.  Note that the\n",
      " |      numbers given to the groups match the order in which the groups\n",
      " |      would be seen when iterating over the groupby object, not the\n",
      " |      order they are first observed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          If False, number in reverse, from number of group - 1 to 0.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Unique numbers for each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      .cumcount : Number the rows in each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": list(\"aaabba\")})\n",
      " |      >>> df\n",
      " |         A\n",
      " |      0  a\n",
      " |      1  a\n",
      " |      2  a\n",
      " |      3  b\n",
      " |      4  b\n",
      " |      5  a\n",
      " |      >>> df.groupby('A').ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    1\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby('A').ngroup(ascending=False)\n",
      " |      0    1\n",
      " |      1    1\n",
      " |      2    1\n",
      " |      3    0\n",
      " |      4    0\n",
      " |      5    1\n",
      " |      dtype: int64\n",
      " |      >>> df.groupby([\"A\", [1,1,2,3,2,1]]).ngroup()\n",
      " |      0    0\n",
      " |      1    0\n",
      " |      2    1\n",
      " |      3    3\n",
      " |      4    2\n",
      " |      5    0\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  nth(self, n: 'PositionalIndexer | tuple', dropna: \"Literal['any', 'all', None]\" = None) -> 'NDFrameT'\n",
      " |      Take the nth row from each group if n is an int, otherwise a subset of rows.\n",
      " |      \n",
      " |      Can be either a call or an index. dropna is not available with index notation.\n",
      " |      Index notation accepts a comma separated list of integers and slices.\n",
      " |      \n",
      " |      If dropna, will take the nth non-null row, dropna is either\n",
      " |      'all' or 'any'; this is equivalent to calling dropna(how=dropna)\n",
      " |      before the groupby.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, slice or list of ints and slices\n",
      " |          A single nth value for the row or a list of nth values or slices.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |              Added slice and lists containing slices.\n",
      " |              Added index notation.\n",
      " |      \n",
      " |      dropna : {'any', 'all', None}, default None\n",
      " |          Apply the specified dropna operation before counting which row is\n",
      " |          the nth row. Only supported if n is an int.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          N-th value within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 1, 2, 1, 2],\n",
      " |      ...                    'B': [np.nan, 2, 3, 4, 5]}, columns=['A', 'B'])\n",
      " |      >>> g = df.groupby('A')\n",
      " |      >>> g.nth(0)\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      2  3.0\n",
      " |      >>> g.nth(1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth(-1)\n",
      " |           B\n",
      " |      A\n",
      " |      1  4.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth([0, 1])\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth(slice(None, -1))\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      \n",
      " |      Index notation may also be used\n",
      " |      \n",
      " |      >>> g.nth[0, 1]\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      2  5.0\n",
      " |      >>> g.nth[:-1]\n",
      " |           B\n",
      " |      A\n",
      " |      1  NaN\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      \n",
      " |      Specifying `dropna` allows count ignoring ``NaN``\n",
      " |      \n",
      " |      >>> g.nth(0, dropna='any')\n",
      " |           B\n",
      " |      A\n",
      " |      1  2.0\n",
      " |      2  3.0\n",
      " |      \n",
      " |      NaNs denote group exhausted when using dropna\n",
      " |      \n",
      " |      >>> g.nth(3, dropna='any')\n",
      " |          B\n",
      " |      A\n",
      " |      1 NaN\n",
      " |      2 NaN\n",
      " |      \n",
      " |      Specifying `as_index=False` in `groupby` keeps the original index.\n",
      " |      \n",
      " |      >>> df.groupby('A', as_index=False).nth(1)\n",
      " |         A    B\n",
      " |      1  1  2.0\n",
      " |      4  2  5.0\n",
      " |  \n",
      " |  ohlc(self) -> 'DataFrame'\n",
      " |      Compute open, high, low and close values of a group, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Open, high, low and close values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  pad(self, limit=None)\n",
      " |      Forward fill the values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      limit : int, optional\n",
      " |          Limit of how many values to fill.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object with missing values filled.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.ffill: Returns Series with minimum number of char in object.\n",
      " |      DataFrame.ffill: Object with missing values filled or None if inplace=True.\n",
      " |      Series.fillna: Fill NaN values of a Series.\n",
      " |      DataFrame.fillna: Fill NaN values of a DataFrame.\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='ffill', limit=None, freq=None, axis=0)\n",
      " |      Calculate pct_change of each value to previous entry in group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Percentage changes within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  prod(self, numeric_only: 'bool | lib.NoDefault' = <no_default>, min_count: 'int' = 0)\n",
      " |      Compute prod of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default True\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed prod of values within each group.\n",
      " |  \n",
      " |  quantile(self, q=0.5, interpolation: 'str' = 'linear')\n",
      " |      Return group values at the given quantile, a la numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          Value(s) between 0 and 1 providing the quantile(s) to compute.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          Method to use when the desired quantile falls between two points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Return type determined by caller of GroupBy object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.quantile : Similar method for Series.\n",
      " |      DataFrame.quantile : Similar method for DataFrame.\n",
      " |      numpy.percentile : NumPy method to compute qth percentile.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     ['a', 1], ['a', 2], ['a', 3],\n",
      " |      ...     ['b', 1], ['b', 3], ['b', 5]\n",
      " |      ... ], columns=['key', 'val'])\n",
      " |      >>> df.groupby('key').quantile()\n",
      " |          val\n",
      " |      key\n",
      " |      a    2.0\n",
      " |      b    3.0\n",
      " |  \n",
      " |  rank(self, method: 'str' = 'average', ascending: 'bool' = True, na_option: 'str' = 'keep', pct: 'bool' = False, axis: 'int' = 0)\n",
      " |      Provide the rank of values within each group.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          * average: average rank of group.\n",
      " |          * min: lowest rank in group.\n",
      " |          * max: highest rank in group.\n",
      " |          * first: ranks assigned in order they appear in the array.\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |      ascending : bool, default True\n",
      " |          False for ranks by high (1) to low (N).\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          * keep: leave NA values where they are.\n",
      " |          * top: smallest rank if ascending.\n",
      " |          * bottom: smallest rank if descending.\n",
      " |      pct : bool, default False\n",
      " |          Compute percentage rank of data within each group.\n",
      " |      axis : int, default 0\n",
      " |          The axis of the object over which to compute the rank.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame with ranking of values within each group\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"group\": [\"a\", \"a\", \"a\", \"a\", \"a\", \"b\", \"b\", \"b\", \"b\", \"b\"],\n",
      " |      ...         \"value\": [2, 4, 2, 3, 5, 1, 2, 4, 1, 5],\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |        group  value\n",
      " |      0     a      2\n",
      " |      1     a      4\n",
      " |      2     a      2\n",
      " |      3     a      3\n",
      " |      4     a      5\n",
      " |      5     b      1\n",
      " |      6     b      2\n",
      " |      7     b      4\n",
      " |      8     b      1\n",
      " |      9     b      5\n",
      " |      >>> for method in ['average', 'min', 'max', 'dense', 'first']:\n",
      " |      ...     df[f'{method}_rank'] = df.groupby('group')['value'].rank(method)\n",
      " |      >>> df\n",
      " |        group  value  average_rank  min_rank  max_rank  dense_rank  first_rank\n",
      " |      0     a      2           1.5       1.0       2.0         1.0         1.0\n",
      " |      1     a      4           4.0       4.0       4.0         3.0         4.0\n",
      " |      2     a      2           1.5       1.0       2.0         1.0         2.0\n",
      " |      3     a      3           3.0       3.0       3.0         2.0         3.0\n",
      " |      4     a      5           5.0       5.0       5.0         4.0         5.0\n",
      " |      5     b      1           1.5       1.0       2.0         1.0         1.0\n",
      " |      6     b      2           3.0       3.0       3.0         2.0         3.0\n",
      " |      7     b      4           4.0       4.0       4.0         3.0         4.0\n",
      " |      8     b      1           1.5       1.0       2.0         1.0         2.0\n",
      " |      9     b      5           5.0       5.0       5.0         4.0         5.0\n",
      " |  \n",
      " |  resample(self, rule, *args, **kwargs)\n",
      " |      Provide resampling when using a TimeGrouper.\n",
      " |      \n",
      " |      Given a grouper, the function resamples it according to a string\n",
      " |      \"string\" -> \"frequency\".\n",
      " |      \n",
      " |      See the :ref:`frequency aliases <timeseries.offset_aliases>`\n",
      " |      documentation for more details.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : str or DateOffset\n",
      " |          The offset string or object representing target grouper conversion.\n",
      " |      *args, **kwargs\n",
      " |          Possible arguments are `how`, `fill_method`, `limit`, `kind` and\n",
      " |          `on`, and other arguments of `TimeGrouper`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Grouper\n",
      " |          Return a new grouper with our resampler appended.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Grouper : Specify a frequency to resample with when\n",
      " |          grouping by a key.\n",
      " |      DatetimeIndex.resample : Frequency conversion and resampling of\n",
      " |          time series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> df = pd.DataFrame(data=4 * [range(2)],\n",
      " |      ...                   index=idx,\n",
      " |      ...                   columns=['a', 'b'])\n",
      " |      >>> df.iloc[2, 0] = 5\n",
      " |      >>> df\n",
      " |                          a  b\n",
      " |      2000-01-01 00:00:00  0  1\n",
      " |      2000-01-01 00:01:00  0  1\n",
      " |      2000-01-01 00:02:00  5  1\n",
      " |      2000-01-01 00:03:00  0  1\n",
      " |      \n",
      " |      Downsample the DataFrame into 3 minute bins and sum the values of\n",
      " |      the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  2\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('30S').sum()\n",
      " |                          a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:00:30  0  0\n",
      " |          2000-01-01 00:01:00  0  1\n",
      " |          2000-01-01 00:01:30  0  0\n",
      " |          2000-01-01 00:02:00  0  0\n",
      " |          2000-01-01 00:02:30  0  0\n",
      " |          2000-01-01 00:03:00  0  1\n",
      " |      5   2000-01-01 00:02:00  5  1\n",
      " |      \n",
      " |      Resample by month. Values are assigned to the month of the period.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('M').sum()\n",
      " |                  a  b\n",
      " |      a\n",
      " |      0   2000-01-31  0  3\n",
      " |      5   2000-01-31  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   1999-12-31 23:57:00  0  1\n",
      " |          2000-01-01 00:00:00  0  2\n",
      " |      5   2000-01-01 00:00:00  5  1\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and close the right side of\n",
      " |      the bin interval, but label each bin using the right edge instead of\n",
      " |      the left.\n",
      " |      \n",
      " |      >>> df.groupby('a').resample('3T', closed='right', label='right').sum()\n",
      " |                               a  b\n",
      " |      a\n",
      " |      0   2000-01-01 00:00:00  0  1\n",
      " |          2000-01-01 00:03:00  0  2\n",
      " |      5   2000-01-01 00:03:00  5  1\n",
      " |  \n",
      " |  rolling(self, *args, **kwargs)\n",
      " |      Return a rolling grouper, providing rolling functionality per group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  sample(self, n: 'int | None' = None, frac: 'float | None' = None, replace: 'bool' = False, weights: 'Sequence | Series | None' = None, random_state: 'RandomState | None' = None)\n",
      " |      Return a random sample of items from each group.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      .. versionadded:: 1.1.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items to return for each group. Cannot be used with\n",
      " |          `frac` and must be no larger than the smallest group unless\n",
      " |          `replace` is True. Default is one if `frac` is None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : list-like, optional\n",
      " |          Default None results in equal probability weighting.\n",
      " |          If passed a list-like then values must have the same length as\n",
      " |          the underlying DataFrame or Series object and will be used as\n",
      " |          sampling probabilities after normalization within each group.\n",
      " |          Values must be non-negative with at least one positive element\n",
      " |          within each group.\n",
      " |      random_state : int, array-like, BitGenerator, np.random.RandomState, np.random.Generator, optional\n",
      " |          If int, array-like, or BitGenerator, seed for random number generator.\n",
      " |          If np.random.RandomState or np.random.Generator, use as given.\n",
      " |      \n",
      " |          .. versionchanged:: 1.4.0\n",
      " |      \n",
      " |              np.random.Generator objects now accepted\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing items randomly\n",
      " |          sampled within each group from the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sample: Generate random samples from a DataFrame object.\n",
      " |      numpy.random.choice: Generate a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\"a\": [\"red\"] * 2 + [\"blue\"] * 2 + [\"black\"] * 2, \"b\": range(6)}\n",
      " |      ... )\n",
      " |      >>> df\n",
      " |             a  b\n",
      " |      0    red  0\n",
      " |      1    red  1\n",
      " |      2   blue  2\n",
      " |      3   blue  3\n",
      " |      4  black  4\n",
      " |      5  black  5\n",
      " |      \n",
      " |      Select one row at random for each distinct value in column a. The\n",
      " |      `random_state` argument can be used to guarantee reproducibility:\n",
      " |      \n",
      " |      >>> df.groupby(\"a\").sample(n=1, random_state=1)\n",
      " |             a  b\n",
      " |      4  black  4\n",
      " |      2   blue  2\n",
      " |      1    red  1\n",
      " |      \n",
      " |      Set `frac` to sample fixed proportions rather than counts:\n",
      " |      \n",
      " |      >>> df.groupby(\"a\")[\"b\"].sample(frac=0.5, random_state=2)\n",
      " |      5    5\n",
      " |      2    2\n",
      " |      0    0\n",
      " |      Name: b, dtype: int64\n",
      " |      \n",
      " |      Control sample probabilities within groups by setting weights:\n",
      " |      \n",
      " |      >>> df.groupby(\"a\").sample(\n",
      " |      ...     n=1,\n",
      " |      ...     weights=[1, 1, 1, 0, 0, 1],\n",
      " |      ...     random_state=1,\n",
      " |      ... )\n",
      " |             a  b\n",
      " |      5  black  5\n",
      " |      2   blue  2\n",
      " |      0    red  0\n",
      " |  \n",
      " |  sem(self, ddof: 'int' = 1)\n",
      " |      Compute standard error of the mean of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : int, default 1\n",
      " |          Degrees of freedom.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Standard error of the mean of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0, fill_value=None)\n",
      " |      Shift each group by periods observations.\n",
      " |      \n",
      " |      If freq is passed, the index will be increased using the periods and the freq.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Number of periods to shift.\n",
      " |      freq : str, optional\n",
      " |          Frequency string.\n",
      " |      axis : axis to shift, default 0\n",
      " |          Shift direction.\n",
      " |      fill_value : optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Object shifted within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      tshift : Shift the time index, using the index’s frequency\n",
      " |          if available.\n",
      " |  \n",
      " |  size(self) -> 'DataFrame | Series'\n",
      " |      Compute group sizes.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame or Series\n",
      " |          Number of rows in each group as a Series if as_index is True\n",
      " |          or a DataFrame if as_index is False.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  std(self, ddof: 'int' = 1, engine: 'str | None' = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute standard deviation of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : int, default 1\n",
      " |          Degrees of freedom.\n",
      " |      \n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the operation through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the operation through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting\n",
      " |            ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{{'nopython': True, 'nogil': False, 'parallel': False}}``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Standard deviation of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  sum(self, numeric_only: 'bool | lib.NoDefault' = <no_default>, min_count: 'int' = 0, engine: 'str | None' = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute sum of group values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      numeric_only : bool, default True\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer\n",
      " |          than ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Computed sum of values within each group.\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Return last n rows of each group.\n",
      " |      \n",
      " |      Similar to ``.apply(lambda x: x.tail(n))``, but it returns a subset of rows\n",
      " |      from the original DataFrame with original index and order preserved\n",
      " |      (``as_index`` flag is ignored).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          If positive: number of entries to include from end of each group.\n",
      " |          If negative: number of entries to exclude from start of each group.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Subset of original Series or DataFrame as determined by n.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],\n",
      " |      ...                   columns=['A', 'B'])\n",
      " |      >>> df.groupby('A').tail(1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |      >>> df.groupby('A').tail(-1)\n",
      " |         A  B\n",
      " |      1  a  2\n",
      " |      3  b  2\n",
      " |  \n",
      " |  var(self, ddof: 'int' = 1, engine: 'str | None' = None, engine_kwargs: 'dict[str, bool] | None' = None)\n",
      " |      Compute variance of groups, excluding missing values.\n",
      " |      \n",
      " |      For multiple groupings, the result index will be a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ddof : int, default 1\n",
      " |          Degrees of freedom.\n",
      " |      \n",
      " |      engine : str, default None\n",
      " |          * ``'cython'`` : Runs the operation through C-extensions from cython.\n",
      " |          * ``'numba'`` : Runs the operation through JIT compiled code from numba.\n",
      " |          * ``None`` : Defaults to ``'cython'`` or globally setting\n",
      " |            ``compute.use_numba``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      engine_kwargs : dict, default None\n",
      " |          * For ``'cython'`` engine, there are no accepted ``engine_kwargs``\n",
      " |          * For ``'numba'`` engine, the engine can accept ``nopython``, ``nogil``\n",
      " |            and ``parallel`` dictionary keys. The values must either be ``True`` or\n",
      " |            ``False``. The default ``engine_kwargs`` for the ``'numba'`` engine is\n",
      " |            ``{{'nopython': True, 'nogil': False, 'parallel': False}}``\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Variance of values within each group.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.groupby : Apply a function groupby to a Series.\n",
      " |      DataFrame.groupby : Apply a function groupby\n",
      " |          to each row or column of a DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.groupby.groupby.GroupBy:\n",
      " |  \n",
      " |  __annotations__ = {'as_index': 'bool', 'grouper': 'ops.BaseGrouper'}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.groupby.groupby.BaseGroupBy:\n",
      " |  \n",
      " |  __iter__(self) -> 'Iterator[tuple[Hashable, NDFrameT]]'\n",
      " |      Groupby iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Generator yielding sequence of (name, subsetted object)\n",
      " |      for each group\n",
      " |  \n",
      " |  __len__(self) -> 'int'\n",
      " |  \n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return a string representation for a particular object.\n",
      " |  \n",
      " |  get_group(self, name, obj=None) -> 'DataFrame | Series'\n",
      " |      Construct DataFrame from group with provided name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object\n",
      " |          The name of the group to get as a DataFrame.\n",
      " |      obj : DataFrame, default None\n",
      " |          The DataFrame to take the DataFrame out of.  If\n",
      " |          it is None, the object groupby was called on will\n",
      " |          be used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      group : same type as obj\n",
      " |  \n",
      " |  pipe(self, func: 'Callable[..., T] | tuple[Callable[..., T], str]', *args, **kwargs) -> 'T'\n",
      " |      Apply a function `func` with arguments to this GroupBy object and return\n",
      " |      the function's result.\n",
      " |      \n",
      " |      Use `.pipe` when you want to improve readability by chaining together\n",
      " |      functions that expect Series, DataFrames, GroupBy or Resampler objects.\n",
      " |      Instead of writing\n",
      " |      \n",
      " |      >>> h(g(f(df.groupby('group')), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.groupby('group')\n",
      " |      ...    .pipe(f)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(h, arg2=b, arg3=c))  # doctest: +SKIP\n",
      " |      \n",
      " |      which is much more readable.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : callable or tuple of (callable, str)\n",
      " |          Function to apply to this GroupBy object or, alternatively,\n",
      " |          a `(callable, data_keyword)` tuple where `data_keyword` is a\n",
      " |          string indicating the keyword of `callable` that expects the\n",
      " |          GroupBy object.\n",
      " |      args : iterable, optional\n",
      " |             Positional arguments passed into `func`.\n",
      " |      kwargs : dict, optional\n",
      " |               A dictionary of keyword arguments passed into `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of `func`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pipe : Apply a function with arguments to a series.\n",
      " |      DataFrame.pipe: Apply a function with arguments to a dataframe.\n",
      " |      apply : Apply function to each group instead of to the\n",
      " |          full GroupBy object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See more `here\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#piping-function-calls>`_\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': 'a b a b'.split(), 'B': [1, 2, 3, 4]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  a  1\n",
      " |      1  b  2\n",
      " |      2  a  3\n",
      " |      3  b  4\n",
      " |      \n",
      " |      To get the difference between each groups maximum and minimum value in one\n",
      " |      pass, you can do\n",
      " |      \n",
      " |      >>> df.groupby('A').pipe(lambda x: x.max() - x.min())\n",
      " |         B\n",
      " |      A\n",
      " |      a  2\n",
      " |      b  2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.groupby.groupby.BaseGroupBy:\n",
      " |  \n",
      " |  groups\n",
      " |      Dict {group name -> group labels}.\n",
      " |  \n",
      " |  indices\n",
      " |      Dict {group name -> group indices}.\n",
      " |  \n",
      " |  ngroups\n",
      " |  \n",
      " |  plot\n",
      " |      Class implementing the .plot attribute for groupby objects.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.SelectionMixin:\n",
      " |  \n",
      " |  ndim\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c12a5a-7f5a-4731-8225-51742037792c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
